{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch读取数据方法总结\n",
    "\n",
    "## 首先，将数据集读取为dataset对象\n",
    "\n",
    "### 数据加载方式\n",
    "\n",
    "在PyTorch中，数据加载可通过自定义的数据集对象。此时数据集对象被抽象为`Dataset`类，实现自定义的数据集需要继承Dataset，并实现两个Python魔法方法：\n",
    "- `__getitem__`：返回一条数据，或一个样本。`obj[index]`等价于`obj.__getitem__(index)`\n",
    "- `__len__`：返回样本的数量。`len(obj)`等价于`obj.__len__()`\n",
    "\n",
    "\n",
    "但是，以上的方法不好，建议采用`ImageFolder`类加载函数，如果想自己定义，可以采用类似一下DogCat类的方法定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import  Image\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(224), # 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "    T.CenterCrop(224), # 从图片中间切出224*224的图片\n",
    "    T.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "    T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # 标准化至[-1, 1]，规定均值和标准差\n",
    "])\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        imgs = os.listdir(root)\n",
    "        self.imgs = [os.path.join(root, img) for img in imgs]\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        label = 0 if 'dog' in img_path.split('/')[-1] else 1\n",
    "        data = Image.open(img_path)\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "dataset = DogCat('./data/dogcat/', transforms=transform)\n",
    "img, label = dataset[0]\n",
    "for img, label in dataset:\n",
    "    print(img.size(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ImageFolder`使用方法\n",
    "`ImageFolder`假设所有的文件按文件夹保存，每个文件夹下存储同一个类别的图片，文件夹名为类名，其构造函数如下：\n",
    "```\n",
    "ImageFolder(root, transform=None, target_transform=None, loader=default_loader)\n",
    "```\n",
    "它主要有四个参数：\n",
    "- `root`：在root指定的路径下寻找图片\n",
    "- `transform`：对PIL Image进行的转换操作，transform的输入是使用loader读取图片的返回对象\n",
    "- `target_transform`：对label的转换\n",
    "- `loader`：给定路径后如何读取图片，默认读取为RGB格式的PIL Image对象\n",
    "\n",
    "label是按照文件夹名顺序排序后存成字典，即{类名:类序号(从0开始)}，一般来说最好直接将文件夹命名为从0开始的数字，这样会和ImageFolder实际的label一致，如果不是这种命名规范，建议看看`self.class_to_idx`属性以了解label和文件夹名的映射关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `transforms`使用方法\n",
    "其中`transforms`模块提供了对PIL `Image`对象和`Tensor`对象的常用操作。\n",
    "\n",
    "对PIL Image的操作包括：\n",
    "- `Scale`：调整图片尺寸，长宽比保持不变\n",
    "- `CenterCrop`、`RandomCrop`、`RandomSizedCrop`： 裁剪图片\n",
    "- `Pad`：填充\n",
    "- `ToTensor`：将PIL Image对象转成Tensor，会自动将[0, 255]归一化至[0, 1]\n",
    "\n",
    "对Tensor的操作包括：\n",
    "- Normalize：标准化，即减均值，除以标准差\n",
    "- ToPILImage：将Tensor转为PIL Image对象\n",
    "\n",
    "如果要对图片进行多个操作，可通过`Compose`函数将这些操作拼接起来，类似于`nn.Sequential`。注意，这些操作定义后是以函数的形式存在，真正使用时需调用它的`__call__`方法，这点类似于`nn.Module`。例如要将图片调整为$224\\times 224$，首先应构建这个操作`trans = Resize((224, 224))`，然后调用`trans(img)`。下面我们就用transforms的这些操作来优化上面实现的dataset。\n",
    "\n",
    "示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import  Image\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "transform = T.Compose([\n",
    "    T.Resize(224), # 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "    T.CenterCrop(224), # 从图片中间切出224*224的图片\n",
    "    T.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "    T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # 标准化至[-1, 1]，规定均值和标准差\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision还提供了两个常用的函数。一个是`make_grid`，它能将多张图片拼接成一个网格中；另一个是`save_img`，它能将Tensor保存成图片。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的查看ImageFolder属性的方法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "dataset = ImageFolder('data/dogcat_2/')\n",
    "# cat文件夹的图片对应label 0，dog对应1\n",
    "dataset.class_to_idx\n",
    "# 所有图片的路径和对应的label\n",
    "dataset.imgs\n",
    "# 没有任何的transform，所以返回的还是PIL Image对象\n",
    "dataset[0][1] # 第一维是第几张图，第二维为1返回label\n",
    "dataset[0][0] # 为0返回图片数据\n",
    "\n",
    "# 加上transform的数据读取取方式\n",
    "normalize = T.Normalize(mean=[0.4, 0.4, 0.4], std=[0.2, 0.2, 0.2])\n",
    "transform  = T.Compose([\n",
    "         T.RandomResizedCrop(224),\n",
    "         T.RandomHorizontalFlip(),\n",
    "         T.ToTensor(),\n",
    "         normalize,\n",
    "])\n",
    "dataset = ImageFolder('data/dogcat_2/', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用DataLoader将读取到的dataset转化为minibatch\n",
    "\n",
    "### dataloader\n",
    "DataLoader的函数定义如下： \n",
    "`DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False)`\n",
    "\n",
    "- dataset：加载的数据集(Dataset对象)\n",
    "- batch_size：batch size\n",
    "- shuffle:：是否将数据打乱\n",
    "- sampler： 样本抽样，后续会详细介绍\n",
    "- num_workers：使用多进程加载的进程数，0代表不使用多进程\n",
    "- collate_fn： 如何将多个样本数据拼接成一个batch，一般使用默认的拼接方式即可\n",
    "- pin_memory：是否将数据保存在pin memory区，pin memory中的数据转到GPU会快一些\n",
    "- drop_last：dataset中的数据个数可能不是batch_size的整数倍，drop_last为True会将多出来不足一个batch的数据丢弃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader是一个可迭代的对象，意味着我们可以像使用迭代器一样使用它，例如：\n",
    "```python\n",
    "for batch_datas, batch_labels in dataloader:\n",
    "    train()\n",
    "```\n",
    "或\n",
    "```\n",
    "dataiter = iter(dataloader)\n",
    "batch_datas, batch_labesl = next(dataiter)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader里面并没有太多的魔法方法，它封装了Python的标准库`multiprocessing`，使其能够实现多进程加速。在此提几点关于Dataset和DataLoader使用方面的建议：\n",
    "1. 高负载的操作放在`__getitem__`中，如加载图片等。\n",
    "2. dataset中应尽量只包含只读对象，避免修改任何可变对象，利用多线程进行操作。\n",
    "\n",
    "第一点是因为多进程会并行的调用`__getitem__`函数，将负载高的放在`__getitem__`函数中能够实现并行加速。\n",
    "第二点是因为dataloader使用多进程加载，如果在`Dataset`实现中使用了可变对象，可能会有意想不到的冲突。在多线程/多进程中，修改一个可变对象，需要加锁，但是dataloader的设计使得其很难加锁（在实际使用中也应尽量避免锁的存在），因此最好避免在dataset中修改可变对象。例如下面就是一个不好的例子，在多进程处理中`self.num`可能与预期不符，这种问题不会报错，因此难以发现。如果一定要修改可变对象，建议使用Python标准库`Queue`中的相关数据结构。\n",
    "\n",
    "```python\n",
    "class BadDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.datas = range(100)\n",
    "        self.num = 0 # 取数据的次数\n",
    "    def __getitem__(self, index):\n",
    "        self.num += 1\n",
    "        return self.datas[index]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch中还单独提供了一个`sampler`模块，用来对数据进行采样。常用的有随机采样器：`RandomSampler`，当dataloader的`shuffle`参数为True时，系统会自动调用这个采样器，实现打乱数据。默认的是采用`SequentialSampler`，它会按顺序一个一个进行采样。这里介绍另外一个很有用的采样方法：\n",
    "`WeightedRandomSampler`，它会根据每个样本的权重选取数据，在样本比例不均衡的问题中，可用它来进行重采样。\n",
    "\n",
    "构建`WeightedRandomSampler`时需提供两个参数：每个样本的权重`weights`、共选取的样本总数`num_samples`，以及一个可选参数`replacement`。权重越大的样本被选中的概率越大，待选取的样本数目一般小于全部的样本数目。`replacement`用于指定是否可以重复选取某一个样本，默认为True，即允许在一个epoch中重复采样某一个数据。如果设为False，则当某一类的样本被全部选取完，但其样本数目仍未达到num_samples时，sampler将不会再从该类中选择数据，此时可能导致`weights`参数失效。下面举例说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogCat('data/dogcat/', transforms=transform)\n",
    "\n",
    "# 狗的图片被取出的概率是猫的概率的两倍\n",
    "# 两类图片被取出的概率与weights的绝对大小无关，只和比值有关\n",
    "weights = [2 if label == 1 else 1 for data, label in dataset]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import  WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(weights,\\\n",
    "                                num_samples=9,\\\n",
    "                                replacement=True)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=3,\n",
    "                        sampler=sampler)\n",
    "for datas, labels in dataloader:\n",
    "    print(labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算机视觉工具包：torchvision\n",
    "\n",
    "torchvision主要包含三部分：\n",
    "\n",
    "- models：提供深度学习中各种经典网络的网络结构以及预训练好的模型，包括`AlexNet`、VGG系列、ResNet系列、Inception系列等。\n",
    "- datasets： 提供常用的数据集加载，设计上都是继承`torhc.utils.data.Dataset`，主要包括`MNIST`、`CIFAR10/100`、`ImageNet`、`COCO`等。\n",
    "- transforms：提供常用的数据预处理操作，主要包括对Tensor以及PIL Image对象的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "# 加载预训练好的模型，如果不存在会进行下载\n",
    "# 预训练好的模型保存在 ~/.torch/models/下面\n",
    "resnet34 = models.resnet34(pretrained=True, num_classes=1000)\n",
    "\n",
    "# 修改最后的全连接层为10分类问题（默认是ImageNet上的1000分类）\n",
    "resnet34.fc=nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "# 指定数据集路径为data，如果数据集不存在则进行下载\n",
    "# 通过train=False获取测试集\n",
    "dataset = datasets.MNIST('data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms中涵盖了大部分对Tensor和PIL Image的常用处理，这些已在上文提到，这里就不再详细介绍。需要注意的是转换分为两步，第一步：构建转换操作，例如`transf = transforms.Normalize(mean=x, std=y)`，第二步：执行转换操作，例如`output = transf(input)`。另外还可将多个处理操作用Compose拼接起来，形成一个处理转换流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理中遇到的异常情况\n",
    "\n",
    "### 样本无法读取\n",
    "\n",
    "在数据处理中，有时会出现某个样本无法读取等问题，比如某张图片损坏。这时在`__getitem__`函数中将出现异常，此时最好的解决方案即是将出错的样本剔除。如果实在是遇到这种情况无法处理，则可以返回None对象，然后在`Dataloader`中实现自定义的`collate_fn`，将空对象过滤掉。但要注意，在这种情况下dataloader返回的batch数目会少于batch_size。\n",
    "\n",
    "简而言之，就是自己写`collate_fn`，去除掉每个batch中不合理的数据（比如说第一个图像数据化后第一个元素值<0）\n",
    "方法如下：\n",
    "```python\n",
    "def my_collate_fn(batch):\n",
    "    '''\n",
    "    batch中每个元素形如(data, label)\n",
    "    '''\n",
    "    # 过滤为None的数据\n",
    "    batch = list(filter(lambda x:x[0] is not None, batch))\n",
    "    if len(batch) == 0: return t.Tensor()\n",
    "    return default_collate(batch) # 用默认方式拼接过滤后的batch数据```\n",
    " 再dataloader = DataLoader(dataset, 2, collate_fn=my_collate_fn, num_workers=1,shuffle=True)即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于诸如样本损坏或数据集加载异常等情况，还可以通过其它方式解决。例如但凡遇到异常情况，就随机取一张图片代替：\n",
    "```python\n",
    "class NewDogCat(DogCat):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super(NewDogCat, self).__getitem__(index)\n",
    "        except:\n",
    "            new_index = random.randint(0, len(self)-1)\n",
    "            return self[new_index]\n",
    "```\n",
    "相比较丢弃异常图片而言，这种做法会更好一些，因为它能保证每个batch的数目仍是batch_size。但在大多数情况下，最好的方式还是对数据进行彻底清洗。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程序退出后GPU与内存依然被占用\n",
    "\n",
    "使用Python `multiprocessing`库的另一个问题是，在使用多进程时，如果主程序异常终止（比如用Ctrl+C强行退出），相应的数据加载进程可能无法正常退出。这时你可能会发现程序已经退出了，但GPU显存和内存依旧被占用着，或通过`top`、`ps aux`依旧能够看到已经退出的程序，这时就需要手动强行杀掉进程。建议使用如下命令：\n",
    "\n",
    "```\n",
    "ps x | grep <cmdline> | awk '{print $1}' | xargs kill\n",
    "```\n",
    "\n",
    "- `ps x`：获取当前用户的所有进程\n",
    "- `grep <cmdline>`：找到已经停止的PyTorch程序的进程，例如你是通过python train.py启动的，那你就需要写`grep 'python train.py'`\n",
    "- `awk '{print $1}'`：获取进程的pid\n",
    "- `xargs kill`：杀掉进程，根据需要可能要写成`xargs kill -9`强制杀掉进程\n",
    "\n",
    "在执行这句命令之前，建议先打印确认一下是否会误杀其它进程\n",
    "```\n",
    "ps x | grep <cmdline> | ps x\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化工具\n",
    "\n",
    "## Tensorboard\n",
    "\n",
    "可以使用tensorboard的方法\n",
    "1. 使用Crayon,但其安装麻烦需要用docker，不推荐\n",
    "2. 使用tensorboard_logger。但其支持的功能有限，且需要安装tensorflow和tensorboard_logger，也挺麻烦。\n",
    "  下载地址：<https://github.com/TeamHG-Memex/tensorboard_logger>\n",
    "   - 安装TensorFlow：如果电脑中已经安装完TensorFlow可以跳过这一步，如果电脑中尚未安装，建议安装CPU-Only的版本，具体安装教程参见TensorFlow官网[^1]，或使用pip直接安装，教育网用户则可通过清华的源提高速度[^2]。\n",
    "   - 安装tensorboard_logger：可通过`pip install tensorboard_logger`命令直接安装。\n",
    "   -之后的方法见书\n",
    "\n",
    "3. 导入一个脚本实现tensorboard只需要安装cpu版的tensorflow，通过pip install tensorflow就能够很快安装上，然后只需要复制这个网址里面的代码到你的项目文件目录，新建一个logger.py的文件，将代码复制进去就ok了。然后在你的python文件里面输入from logger import Logger，然后在训练之前定义好想存放tensorboard文件的文件夹，logger = Logger('./logs')这里可以使用任何文件夹存放tensorboard文件。\n",
    "具体方法<https://zhuanlan.zhihu.com/p/27624517>\n",
    "\n",
    "4. 采用TensorboardX[^4]，它封装了更多的Tensorboard接口，支持记录标量，图片，直方图，声音，文本，计算图和embedding等信息，几乎是和TensorFlow的Tensorboard完全一样的功能，使用接口甚至比TensorFlow的Tensorboard接口还要简单。（建议实施这种方法）\n",
    "\n",
    "[^4]: https://github.com/lanpa/tensorboard-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visdom\n",
    "\n",
    "Visdom可以创造、组织和共享多种数据的可视化，包括数值、图像、文本，甚至是视频，其支持PyTorch、Torch及Numpy。用户可通过编程组织可视化空间，或通过用户接口为生动数据打造仪表板，检查实验结果或调试代码。\n",
    "\n",
    "Visdom中有两个重要概念：\n",
    "- env：环境。不同环境的可视化结果相互隔离，互不影响，在使用时如果不指定env，默认使用`main`。不同用户、不同程序一般使用不同的env。\n",
    "- pane：窗格。窗格可用于可视化图像、数值或打印文本等，其可以拖动、缩放、保存和关闭。一个程序中可使用同一个env中的不同pane，每个pane可视化或记录某一信息。\n",
    "\n",
    "如图4所示，当前env共有两个pane，一个用于打印log，另一个用于记录损失函数的变化。点击clear按钮可以清空当前env的所有pane，点击save按钮可将当前env保存成json文件，保存路径位于`~/.visdom/`目录下。也可修改env的名字后点击fork，保存当前env的状态至更名后的env。\n",
    "\n",
    "Visdom的安装可通过命令`pip install visdom`。安装完成后，需通过`python -m visdom.server`命令启动visdom服务，或通过`nohup python -m visdom.server &`命令将服务放至后台运行。Visdom服务是一个web server服务，默认绑定8097端口，客户端与服务器间通过tornado进行非阻塞交互。\n",
    "\n",
    "Visdom的使用有两点需要注意的地方：\n",
    "- 需手动指定保存env，可在web界面点击save按钮或在程序中调用save方法，否则visdom服务重启后，env等信息会丢失。\n",
    "- 客户端与服务器之间的交互采用tornado异步框架，可视化操作不会阻塞当前程序，网络异常也不会导致程序退出。\n",
    "\n",
    "Visdom以Plotly为基础，支持丰富的可视化操作，下面举例说明一些最常用的操作。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用GPU加速：CUDA\n",
    "\n",
    "相比于对GPU完全透明的Theano而言，在PyTorch中使用GPU较为复杂，但同时这也意味着对GPU资源更加灵活高效的控制。这部分内容在前面介绍Tensor、Module时大都提到过，这里将做一个总结，并深入介绍相关应用。\n",
    "\n",
    "## 可以采用GPU的数据结构\n",
    "在PyTorch中以下数据结构分为CPU和GPU两个版本：\n",
    "- Tensor\n",
    "- Variable（包括Parameter）\n",
    "- nn.Module（包括常用的layer、loss function，以及容器Sequential等）\n",
    "\n",
    "\n",
    "它们都带有一个`.cuda`方法，调用此方法即可将其转为对应的GPU对象。注意，`tensor.cuda`和`variable.cuda`都会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor/variable的数据还在原来的设备上（CPU）。而`module.cuda`则会将所有的数据都迁移至GPU，并返回自己。所以`module = module.cuda()`和`module.cuda()`所起的作用一致。\n",
    "\n",
    "Variable和nn.Module在GPU与CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。`Variable.cuda`操作实际上是将`variable.data`转移至指定的GPU。而`nn.Module`的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Parameter本质上也是Variable。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于使用GPU的一些建议：\n",
    "- GPU运算很快，但对于很小的运算量来说，并不能体现出它的优势，因此对于一些简单的操作可直接利用CPU完成\n",
    "- 数据在CPU和GPU之间，以及GPU与GPU之间的传递会比较耗时，应当尽量避免\n",
    "- 在进行低精度的计算时，可以考虑`HalfTensor`，它相比于`FloatTensor`能节省一半的显存，但需千万注意数值溢出的情况。\n",
    "- 另外这里需要专门提一下，大部分的损失函数也都属于`nn.Moudle`，但在使用GPU时，很多时候我们都忘记使用它的`.cuda`方法，这在大多数情况下不会报错，因为损失函数本身没有可学习的参数（learnable parameters）。但在某些情况下会出现问题，为了保险起见同时也为了代码更规范，应记得调用`criterion.cuda`。下面举例说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定默认使用哪一块GPU\n",
    "除了调用对象的`.cuda`方法之外，还可以使用`torch.cuda.device`，来指定默认使用哪一块GPU，或使用`torch.set_default_tensor_type`使程序默认使用GPU，不需要手动调用cuda。\n",
    "方法：\n",
    "1. y = t.FloatTensor(2, 3).cuda()（如果未指定使用哪块GPU，默认使用GPU 0）\n",
    "2. with t.cuda.device(1): （指定默认使用GPU 1）\n",
    "3. d = t.randn(2, 3).cuda(0)（指定使用GPU0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果未指定使用哪块GPU，默认使用GPU 0\n",
    "x = t.cuda.FloatTensor(2, 3)\n",
    "# x.get_device() == 0\n",
    "y = t.FloatTensor(2, 3).cuda()\n",
    "# y.get_device() == 0\n",
    "\n",
    "# 指定默认使用GPU 1\n",
    "with t.cuda.device(1):    \n",
    "    # 在GPU 1上构建tensor\n",
    "    a = t.cuda.FloatTensor(2, 3)\n",
    "\n",
    "    # 将tensor转移至GPU 1\n",
    "    b = t.FloatTensor(2, 3).cuda()\n",
    "    print(a.get_device() == b.get_device() == 1 )\n",
    "\n",
    "    c = a + b\n",
    "    print(c.get_device() == 1)\n",
    "\n",
    "    z = x + y\n",
    "    print(z.get_device() == 0)\n",
    "\n",
    "    # 手动指定使用GPU 0\n",
    "    d = t.randn(2, 3).cuda(0)\n",
    "    print(d.get_device() == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果服务器具有多个GPU，`tensor.cuda()`方法会将tensor保存到第一块GPU上，等价于`tensor.cuda(0)`。此时如果想使用第二块GPU，需手动指定`tensor.cuda(1)`，而这需要修改大量代码，很是繁琐。这里有两种替代方法：\n",
    "\n",
    "- 一种是先调用`t.cuda.set_device(1)`指定使用第二块GPU，后续的`.cuda()`都无需更改，切换GPU只需修改这一行代码。\n",
    "- 更推荐的方法是设置环境变量`CUDA_VISIBLE_DEVICES`，例如当`export CUDA_VISIBLE_DEVICE=1`（下标是从0开始，1代表第二块GPU），只使用第二块物理GPU，但在程序中这块GPU会被看成是第一块逻辑GPU，因此此时调用`tensor.cuda()`会将Tensor转移至第二块物理GPU。`CUDA_VISIBLE_DEVICES`还可以指定多个GPU，如`export CUDA_VISIBLE_DEVICES=0,2,3`，那么第一、三、四块物理GPU会被映射成第一、二、三块逻辑GPU，`tensor.cuda(1)`会将Tensor转移到第三块物理GPU上。\n",
    "\n",
    "设置`CUDA_VISIBLE_DEVICES`有两种方法，一种是在命令行中`CUDA_VISIBLE_DEVICES=0,1 python main.py`，一种是在程序中`import os;os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"`。如果使用IPython或者Jupyter notebook，还可以使用`%env CUDA_VISIBLE_DEVICES=1,2`来设置环境变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 持久化\n",
    "在PyTorch中，以下对象可以持久化到硬盘，并能通过相应的方法加载到内存中：\n",
    "- Tensor\n",
    "- Variable\n",
    "- nn.Module\n",
    "- Optimizer\n",
    "\n",
    "本质上上述这些信息最终都是保存成Tensor。Tensor的保存和加载十分的简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的pickle模块，在load时还可将GPU tensor映射到CPU或其它GPU上。\n",
    "\n",
    "我们可以通过`t.save(obj, file_name)`等方法保存任意可序列化的对象，然后通过`obj = t.load(file_name)`方法加载保存的数据。对于Module和Optimizer对象，这里建议保存对应的`state_dict`，而不是直接保存整个Module/Optimizer对象。Optimizer对象保存的主要是参数，以及动量信息，通过加载之前的动量信息，能够有效地减少模型震荡，下面举例说明。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.Tensor(3, 4)\n",
    "if t.cuda.is_available():\n",
    "        a = a.cuda(1) # 把a转为GPU1上的tensor,\n",
    "        t.save(a,'a.pth')\n",
    "        \n",
    "        # 加载为b, 存储于GPU1上(因为保存时tensor就在GPU1上)\n",
    "        b = t.load('a.pth')\n",
    "        \n",
    "        # 加载为c, 存储于CPU\n",
    "        c = t.load('a.pth', map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        # 加载为d, 存储于GPU0上\n",
    "        d = t.load('a.pth', map_location={'cuda:1':'cuda:0'})\n",
    "\n",
    "# Module对象的保存与加载\n",
    "t.save(model.state_dict(), 'squeezenet.pth')\n",
    "model.load_state_dict(t.load('squeezenet.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorchpy36]",
   "language": "python",
   "name": "conda-env-pytorchpy36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
