{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(name)s:%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class residualblock(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channel,out_channel,stride=1,shortcut=None):\n",
    "        super(residualblock, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.left = nn.Sequential(\n",
    "#             nn.Conv2d(in_channel,out_channel,kernel_size,stride),之前都没加padding 导致计算后维度改变\n",
    "#             nn.Conv2d(in_channel,out_channel,stride,1,bias=False),\n",
    "            nn.Conv2d(in_channel,out_channel,3,stride,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channel,out_channel,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "        )\n",
    "        self.right = shortcut\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        output = self.left(x)\n",
    "#         residual = x if self.right == None else self.right shortcut是一个nn.module类再添加各种层之后实例化的结果，我们应该向类输入x\n",
    "        \n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        \n",
    "        output = output + residual\n",
    "       \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,num_class = 1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,2,3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "#             nn.MaxPool2d( 3,2,1)#这里pooling的kernelsize为3，所以要加padding=1\n",
    "            nn.MaxPool2d( 2,2)#尝试了一下不用3*3模板\n",
    "        )\n",
    "#         self.layer1 = make_layer(self,64,64,3,3)类内调用类内的函数要用self.function的形式\n",
    "#         self.layer2 = make_layer(self,64,128,4,3)\n",
    "#         self.layer3= make_layer(self,128,256,6,3)\n",
    "#         self.layer4= make_layer(self,256,512,3,3)\n",
    "        self.layer1 = self.make_layer(64,64,3,1)\n",
    "        self.layer2 = self.make_layer(64,128,4,2)\n",
    "        self.layer3= self.make_layer(128,256,6,2)\n",
    "        self.layer4= self.make_layer(256,512,3,2)\n",
    "        self.fc = nn.Linear(512, 1000)\n",
    "        \n",
    "    def make_layer(self,in_channel,out_channel,block_num,stride):\n",
    "        \n",
    "        if out_channel != in_channel:\n",
    "            shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel,3,2,1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            )\n",
    "        else:\n",
    "             shortcut = None\n",
    "        layer = []\n",
    "        layer.append(residualblock(in_channel,out_channel,stride,shortcut))\n",
    "        for i in range(1,block_num):\n",
    "            layer.append(residualblock(out_channel,out_channel))\n",
    "        return nn.Sequential(*layer)\n",
    "#         layer = nn.ModuleList([])\n",
    "#         layer.append(residualblock(in_channel,out_channel,stride,shortcut))\n",
    "#         for i in range(1,block_num):\n",
    "#             layer.append(residualblock(out_channel,out_channel))\n",
    "#         return layer\n",
    "    \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        print(x.size())\n",
    "        x = self.pre(x)\n",
    "        print(x.size())\n",
    "        x = self.layer1(x)\n",
    "        print(x.size())\n",
    "        x = self.layer2(x)\n",
    "        print(x.size())\n",
    "        x = self.layer3(x)\n",
    "        print(x.size())\n",
    "        x = self.layer4(x)\n",
    "        print(x.size())\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modulelist的功能主要在于以self.moudlelist的形式构造一个子layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "model = ResNet()\n",
    "input  = t.autograd.Variable(t.randn(1, 3, 224, 224))\n",
    "o = model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以后还是写好计划"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorchpy36]",
   "language": "python",
   "name": "conda-env-pytorchpy36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
