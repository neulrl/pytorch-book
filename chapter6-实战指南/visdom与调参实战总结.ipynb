{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要记录chapter6-实战指南中visdom用于可视化的使用方法：\n",
    "\n",
    "首先，作者定义了一个visualizer类用于封装visdom的基本操作（我也不知道为什么这么做，我个人觉得直接调用函数更简单，可能是这样把所有显示的函数集中在一起更好查看吧）\n",
    "\n",
    "在这个类中定义了显示图片散点以及打印信息的方法。\n",
    "\n",
    "我要记录的问题主要有哪些：\n",
    "\n",
    "- 在一个程序里，我主要是记录哪些信息\n",
    "- 这些信息通过哪些方式去完成记录，如何输出到visdom中\n",
    "- 如何根据visdom的输出效果调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在深度学习程序里，我需要记录哪些信息\n",
    "\n",
    "记录的信息有loss,若干个个batch输出一次；val计算出的accuracy,test计算出的accuracy；还有当前的loss或者val的 accuracy对应的batch号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这些信息通过哪些方式去完成记录\n",
    "\n",
    "- loss可以记录在一个列表里，作者用的方法是用torchnet的一个class：meter，这个可以通过调用meter.AverageValueMeter用列表的方式输入loss，通过调用value输出均值（方差），通过reset方法清零。(这种方法的好处应该就是可以输出多张类型的数据比如均值方差都可以)\n",
    "```python\n",
    "loss_meter = meter.AverageValueMeter()\n",
    "loss_meter.reset()\n",
    "loss_meter.add(loss.data[0])\n",
    "if ii%opt.print_freq==opt.print_freq-1:\n",
    "    vis.plot('loss', loss_meter.value()[0])\n",
    "```\n",
    "\n",
    "- val_accuracy是通过混淆矩阵来计算的，作者同样用的方法是用torchnet的一个class：meter，通过调用meter.ConfusionMeter()将预测结果与标签值输入meter.ConfusionMeter()，之后计算出混淆矩阵（即真psoitive，假psoitive，真nagetive,假nagetive组成的矩阵）PS:这里我想不明白为什么要用meter这个类。\n",
    "```python\n",
    "cm_value = confusion_matrix.value()\n",
    "confusion_matrix.add(score.data, target.data)\n",
    "val_accuracy = 100. * (cm_value[0][0] + cm_value[1][1]) / (cm_value.sum())\n",
    "vis.plot('val_accuracy',val_accuracy)\n",
    "```\n",
    "- loss也可以直接存在一个数里，每n次输出一下就可以了，多分类问题也可以取max之后与label比较计算precsion.\n",
    "\n",
    "```python\n",
    " running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "```\n",
    "```python\n",
    "_, predicted = t.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        \n",
    "        # 画的第几个数，相当于横座标\n",
    "        # 保存（’loss',23） 即loss的第23个点\n",
    "        self.index = {} \n",
    "        self.log_text = ''\n",
    "def plot(self, name, y,**kwargs):\n",
    "        '''\n",
    "        self.plot('loss',1.00)\n",
    "        '''\n",
    "        x = self.index.get(name, 0)#检索index 字典里是否有存储‘loss’的值，没有的话，设为0\n",
    "        self.vis.line(Y=np.array([y]), X=np.array([x]),#\n",
    "                      win=name,\n",
    "                      opts=dict(title=name),\n",
    "                      update=None if x == 0 else 'append',\n",
    "                      **kwargs\n",
    "                      )\n",
    "        self.index[name] = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结：\n",
    "总而言之，loss是直接计算出来，每n次计算一次均值，之后把loss均值以及本次loss均值对应的batch号输入到 visdom.Visdom.line里就可以了\n",
    "val_accuracy同样,只需输入val_accuracy以及对应的对应的batch号，只不过可以利用混淆矩阵计算accuracy(把真正例与真反例都算作分类正确的结果)\n",
    "\n",
    "我写的话，还是把作者的visualize.py拷贝过来吧，调用plot就可以了。要不然就是在epoch外面设置batch编号或者在函数内部设置一个静态变量作为batch变量（等晚上看看GPU可以用了之后就自己试一下）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 之后如何使用：\n",
    "- 把visualize.py文件放到主文件夹的utils子文件夹中，加上__init__.py文件中间加上from .visualize import Visualizer\n",
    "- 之后，主文件中```from utils.visualize import Visualizer```\n",
    "- 之后：```vis = Visualizer(opt.env)```配置visdom的环境\n",
    "- 计算完loss 或val_accuracy之后，将数值存储起来，固定周期计算一下均值，与当前batch编号一起输出到visdom中\n",
    "```python\n",
    "vis.plot('loss', loss_meter.value()[0])```\n",
    "或\n",
    "```vis.plot('val_accuracy',val_accuracy)```\n",
    "即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3如何根据结果调参\n",
    "### 调参之前应该做的事\n",
    "\n",
    "1. 可视化训练过程中每个step（batch）的loss。如果是分类任务，可以顺便可视化出每个batch的准确率（不均衡数据可视化F1-score）。\n",
    "2. 将训练日志在打印到屏幕上的同时也写入到本地磁盘。如果能实时同步写入那更好了（在python中可以用logging模块可以轻松实现。一个handler输出到屏幕，再设置一个handler输出到磁盘即可）。\n",
    "3. 借助tensorflow里的FLAGS模块或者python-fire工具将你的训练脚本封装成命令行工具。\n",
    "4. 代码中完成tensorboard等训练过程可视化环境的配置，最少要可视化出训练loss曲线。\n",
    "5. 如果使用tensorflow，记得设置GPU内存动态增长（除非你只有一个GPU并且你确信一个训练任务会消耗GPU的一大半显存）\n",
    "6. 初始调参阶段记得关闭L2、Dropout等用来调高模型泛化能力的超参数呐，它们很可能极大的影响loss曲线，干扰你的重要超参数的选取。然后根据自己的任务的量级，预估一个合理的batch size（一般来说64是个不错的初始点。数据集不均衡的话建议使用更大一点的值，数据集不大模型又不是太小的情况下建议使用更小一些的值）。如果对网络参数的随机初始化策略缺乏经验知识（知识来源于相关任务的论文实验细节或开源项目等），可以使用He方法[1]（使用ReLU激活时）或Xavier方法[2]来进行网络参数初始化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 方法见visdom_exercise文件\n",
    "2. 待学\n",
    "3. \n",
    "在讲解主程序`main.py`之前，我们先来看看2017年3月谷歌开源的一个命令行工具`fire`[^3] ，通过`pip install fire`即可安装。下面来看看`fire`的基础用法，假设`example.py`文件内容如下：\n",
    "\n",
    "```python\n",
    "import fire\n",
    "\n",
    "def add(x, y):\n",
    "  return x + y\n",
    "  \n",
    "def mul(**kwargs):\n",
    "    a = kwargs['a']\n",
    "    b = kwargs['b']\n",
    "    return a * b\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  fire.Fire()\n",
    "```\n",
    "\n",
    "那么我们可以使用：\n",
    "\n",
    "```bash\n",
    "python example.py add 1 2 # 执行add(1, 2)\n",
    "python example.py mul --a=1 --b=2 # 执行mul(a=1, b=2), kwargs={'a':1, 'b':2}\n",
    "python example.py add --x=1 --y==2 # 执行add(x=1, y=2)\n",
    "```\n",
    "\n",
    "可见，只要在程序中运行`fire.Fire()`，即可使用命令行参数`python file <function> [args,] {--kwargs,}`。fire还支持更多的高级功能，具体请参考官方指南[^4] 。\n",
    "\n",
    "[^3]: https://github.com/google/python-fire\n",
    "[^4]: https://github.com/google/python-fire/blob/master/doc/guide.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorchpy36]",
   "language": "python",
   "name": "conda-env-pytorchpy36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
